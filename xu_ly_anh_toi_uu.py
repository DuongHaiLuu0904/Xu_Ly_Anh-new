
import numpy as np
try:
    from scipy.ndimage import zoom
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    print("‚ö†Ô∏è scipy kh√¥ng c√≥ s·∫µn - s·∫Ω d√πng resize th·ªß c√¥ng (ch·∫≠m h∆°n)")


def resize_image(image, new_width, new_height):
    """
    Resize ·∫£nh b·∫±ng ph∆∞∆°ng ph√°p bilinear interpolation
    
    Tham s·ªë:
        image: ·∫¢nh ƒë·∫ßu v√†o (numpy array)
        new_width: Chi·ªÅu r·ªông m·ªõi
        new_height: Chi·ªÅu cao m·ªõi
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh ƒë√£ resize
    """
    height, width = image.shape[:2]
    
    # T√≠nh t·ª∑ l·ªá scale
    scale_y = height / new_height
    scale_x = width / new_width
    
    # T·∫°o ·∫£nh output
    if len(image.shape) == 3:
        resized = np.zeros((new_height, new_width, image.shape[2]), dtype=image.dtype)
    else:
        resized = np.zeros((new_height, new_width), dtype=image.dtype)
    
    # Bilinear interpolation
    for i in range(new_height):
        for j in range(new_width):
            # T√¨m v·ªã tr√≠ trong ·∫£nh g·ªëc
            src_y = i * scale_y
            src_x = j * scale_x
            
            # T√¨m 4 ƒëi·ªÉm l√¢n c·∫≠n
            y0 = int(np.floor(src_y))
            y1 = min(y0 + 1, height - 1)
            x0 = int(np.floor(src_x))
            x1 = min(x0 + 1, width - 1)
            
            # T√≠nh tr·ªçng s·ªë
            dy = src_y - y0
            dx = src_x - x0
            
            # Interpolation
            if len(image.shape) == 3:
                for c in range(image.shape[2]):
                    val = (image[y0, x0, c] * (1 - dx) * (1 - dy) +
                           image[y0, x1, c] * dx * (1 - dy) +
                           image[y1, x0, c] * (1 - dx) * dy +
                           image[y1, x1, c] * dx * dy)
                    resized[i, j, c] = val
            else:
                val = (image[y0, x0] * (1 - dx) * (1 - dy) +
                       image[y0, x1] * dx * (1 - dy) +
                       image[y1, x0] * (1 - dx) * dy +
                       image[y1, x1] * dx * dy)
                resized[i, j] = val
    
    return resized


def multiply_images(image1, image2):
    """
    Nh√¢n hai ·∫£nh v·ªõi nhau (element-wise multiplication)
    
    Tham s·ªë:
        image1: ·∫¢nh th·ª© nh·∫•t (numpy array)
        image2: ·∫¢nh th·ª© hai (numpy array)
    
    Tr·∫£ v·ªÅ:
        K·∫øt qu·∫£ nh√¢n hai ·∫£nh
    """
    return image1 * image2


def rgb_to_grayscale(image):
    """
    Chuy·ªÉn RGB sang grayscale
    
    Tham s·ªë:
        image: ·∫¢nh BGR (OpenCV format)
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh x√°m (numpy array)
    """
    if len(image.shape) == 3:
        b = image[:, :, 0].astype(np.float32)
        g = image[:, :, 1].astype(np.float32)
        r = image[:, :, 2].astype(np.float32)
        gray = 0.114 * b + 0.587 * g + 0.299 * r
        return gray.astype(np.uint8)
    return image


def invert_image(image):
    return 255 - image


def create_gaussian_kernel(size, sigma):
    """
    T·∫°o kernel Gaussian
    
    Tham s·ªë:
        size: K√≠ch th∆∞·ªõc kernel (s·ªë l·∫ª)
        sigma: ƒê·ªô l·ªách chu·∫©n
    
    Tr·∫£ v·ªÅ:
        Kernel Gaussian ƒë√£ chu·∫©n h√≥a
    """
    size = size if size % 2 == 1 else size + 1
    center = size // 2
    kernel = np.zeros((size, size), dtype=np.float32)
    
    for i in range(size):
        for j in range(size):
            x = i - center
            y = j - center
            kernel[i, j] = np.exp(-(x*x + y*y) / (2 * sigma * sigma))
    
    kernel = kernel / np.sum(kernel)
    return kernel


def apply_convolution(image, kernel):
    """
    √Åp d·ª•ng convolution 2D
    
    Tham s·ªë:
        image: ·∫¢nh ƒë·∫ßu v√†o
        kernel: Kernel convolution
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh sau khi convolution
    """
    height, width = image.shape
    k_height, k_width = kernel.shape
    pad_h = k_height // 2
    pad_w = k_width // 2
    
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')
    output = np.zeros((height, width), dtype=np.float32)
    
    for i in range(height):
        for j in range(width):
            region = padded[i:i+k_height, j:j+k_width]
            output[i, j] = np.sum(region * kernel)
    
    return np.clip(output, 0, 255).astype(np.uint8)


def gaussian_blur(image, kernel_size, sigma):
    """
    L√†m m·ªù Gaussian
    
    Tham s·ªë:
        image: ·∫¢nh ƒë·∫ßu v√†o
        kernel_size: K√≠ch th∆∞·ªõc kernel
        sigma: ƒê·ªô l·ªách chu·∫©n
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh ƒë√£ l√†m m·ªù
    """
    kernel = create_gaussian_kernel(kernel_size, sigma)
    return apply_convolution(image, kernel)


def bilateral_filter_optimized(image, d, sigma_color, sigma_space):
    """
    - Downsampling t·ª± ƒë·ªông (·∫£nh > 500px)
    - Pre-compute spatial weights (t√≠nh 1 l·∫ßn)
    - Vectorization (NumPy operations)
    - Batch processing (50 d√≤ng/l·∫ßn)
    
    Tham s·ªë:
        image: ·∫¢nh x√°m ƒë·∫ßu v√†o
        d: ƒê∆∞·ªùng k√≠nh v√πng l√¢n c·∫≠n
        sigma_color: ƒê·ªô l·ªách chu·∫©n m√†u
        sigma_space: ƒê·ªô l·ªách chu·∫©n kh√¥ng gian
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh ƒë√£ l√†m m·ªãn
    """
    height, width = image.shape
    
    # T·ªêI ∆ØU 1: Downsampling
    scale_factor = 1.0
    if max(height, width) > 500:
        scale_factor = 500.0 / max(height, width)
        new_h = int(height * scale_factor)
        new_w = int(width * scale_factor)
        
        if HAS_SCIPY:
            image_small = zoom(image, scale_factor, order=1)
        else:
            # Resize th·ªß c√¥ng
            step_h = max(1, int(1 / scale_factor))
            step_w = max(1, int(1 / scale_factor))
            image_small = image[::step_h, ::step_w]
        
        print(f"  üìâ Downsampling: {height}x{width} ‚Üí {new_h}x{new_w} (tƒÉng t·ªëc x{1/scale_factor:.1f})")
    else:
        image_small = image
    
    h_small, w_small = image_small.shape
    radius = d // 2
    
    # T·ªêI ∆ØU 2: Pre-compute spatial weights (ch·ªâ t√≠nh 1 l·∫ßn)
    spatial_weights = np.zeros((d, d), dtype=np.float32)
    for ki in range(-radius, radius + 1):
        for kj in range(-radius, radius + 1):
            spatial_dist = ki*ki + kj*kj
            spatial_weights[ki + radius, kj + radius] = np.exp(
                -spatial_dist / (2 * sigma_space * sigma_space)
            )
    
    padded = np.pad(image_small, radius, mode='reflect')
    output = np.zeros_like(image_small, dtype=np.float32)
    
    
    # T·ªêI ∆ØU 3: Batch processing
    batch_size = 50
    
    for batch_start in range(0, h_small, batch_size):
        batch_end = min(batch_start + batch_size, h_small)
        
        # T·ªêI ∆ØU 4: Vectorization
        for i in range(batch_start, batch_end):
            for j in range(w_small):
                center_value = padded[i + radius, j + radius]
                
                # T·ªêI ∆ØU 5: L·∫•y to√†n b·ªô v√πng m·ªôt l·∫ßn
                region = padded[i:i+d, j:j+d].astype(np.float32)
                
                # Vectorized computation
                value_diffs = region - float(center_value)
                range_weights = np.exp(
                    -(value_diffs * value_diffs) / (2 * sigma_color * sigma_color)
                )
                
                combined_weights = spatial_weights * range_weights
                weight_sum = np.sum(combined_weights)
                
                if weight_sum > 0:
                    output[i, j] = np.sum(region * combined_weights) / weight_sum
                else:
                    output[i, j] = center_value
        
        progress = int((batch_end) / h_small * 100)
        print(f"    Ti·∫øn ƒë·ªô: {progress}%", end='\r')
    
    print()
    
    # T·ªêI ∆ØU 6: Upsampling n·∫øu c·∫ßn
    if scale_factor < 1.0:
        if HAS_SCIPY:
            output = zoom(output, 1.0/scale_factor, order=1)
            output = output[:height, :width]
        else:
            # Upsampling th·ªß c√¥ng
            output_full = np.zeros((height, width), dtype=np.float32)
            for i in range(height):
                for j in range(width):
                    i_small = int(i * scale_factor)
                    j_small = int(j * scale_factor)
                    output_full[i, j] = output[min(i_small, h_small-1), min(j_small, w_small-1)]
            output = output_full
        
        print(f"  üìà Upsampling: {h_small}x{w_small} ‚Üí {height}x{width}")
    
    return np.clip(output, 0, 255).astype(np.uint8)


def detect_edges(image):
    """
    Ph√°t hi·ªán c·∫°nh b·∫±ng Sobel operator
    
    Tham s·ªë:
        image: ·∫¢nh x√°m
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh c·∫°nh
    """
    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)
    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)
    
    height, width = image.shape
    padded = np.pad(image, 1, mode='reflect')
    
    edges_x = np.zeros_like(image, dtype=np.float32)
    edges_y = np.zeros_like(image, dtype=np.float32)
    
    for i in range(height):
        for j in range(width):
            region = padded[i:i+3, j:j+3].astype(np.float32)
            edges_x[i, j] = np.sum(region * sobel_x)
            edges_y[i, j] = np.sum(region * sobel_y)
    
    edges = np.sqrt(edges_x**2 + edges_y**2)
    
    # TƒÉng c∆∞·ªùng ƒë·ªô ƒë·∫≠m c·ªßa edges
    edges = edges * 2.5
    edges = np.clip(edges, 0, 255).astype(np.uint8)
    
    return edges


def color_dodge(base, blend):
    """
    Color dodge blending mode
    
    Tham s·ªë:
        base: ·∫¢nh n·ªÅn
        blend: ·∫¢nh blend
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh sau blending
    """
    base_float = base.astype(np.float32)
    blend_float = blend.astype(np.float32)
    
    inverted_blend = 255.0 - blend_float
    inverted_blend = np.where(inverted_blend == 0, 1, inverted_blend)
    
    result = (base_float / inverted_blend) * 255.0
    result = np.clip(result, 0, 255)
    
    return result.astype(np.uint8)


def adjust_contrast(image, contrast_factor):
    """
    ƒêi·ªÅu ch·ªânh contrast
    
    Tham s·ªë:
        image: ·∫¢nh ƒë·∫ßu v√†o
        contrast_factor: H·ªá s·ªë contrast (1.0 = kh√¥ng thay ƒë·ªïi)
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh ƒë√£ ƒëi·ªÅu ch·ªânh contrast
    """
    img_float = image.astype(np.float32)
    adjusted = (img_float - 128.0) * contrast_factor + 128.0
    adjusted = np.clip(adjusted, 0, 255)
    return adjusted.astype(np.uint8)


def convert_to_sketch(image_bgr, gaussian_kernel=15, gaussian_sigma=3,
                     bilateral_kernel=5, sigma_color=50, sigma_space=50,
                     contrast=1.1, brightness=50):
    """
    Pipeline ch√≠nh: Chuy·ªÉn ·∫£nh m√†u th√†nh ph√°c th·∫£o
    
    Tham s·ªë:
        image_bgr: ·∫¢nh BGR (OpenCV format)
        gaussian_kernel: K√≠ch th∆∞·ªõc kernel Gaussian
        gaussian_sigma: Sigma cho Gaussian
        bilateral_kernel: K√≠ch th∆∞·ªõc kernel Bilateral
        sigma_color: Sigma m√†u cho Bilateral
        sigma_space: Sigma kh√¥ng gian cho Bilateral
        contrast: H·ªá s·ªë t∆∞∆°ng ph·∫£n (1.0 = kh√¥ng ƒë·ªïi)
        brightness: ƒê·ªô s√°ng th√™m v√†o (0-100)
    
    Tr·∫£ v·ªÅ:
        ·∫¢nh ph√°c th·∫£o
    """
    import time
    
    print("\n" + "="*60)
    print("B·∫ÆT ƒê·∫¶U X·ª¨ L√ù (LOGIC T·ªêI ∆ØU)")
    print("="*60)
    
    total_start = time.time()
    
    # B∆∞·ªõc 1: Chuy·ªÉn sang ·∫£nh x√°m
    print("\n[1/9] Chuy·ªÉn ·∫£nh x√°m...")
    t1 = time.time()
    gray_image = rgb_to_grayscale(image_bgr)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t1:.2f}s)")
    
    # B∆∞·ªõc 2: ƒê·∫£o ng∆∞·ª£c ·∫£nh x√°m
    print("\n[2/9] ƒê·∫£o ng∆∞·ª£c ·∫£nh x√°m...")
    t2 = time.time()
    inverted_gray = invert_image(gray_image)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t2:.2f}s)")
    
    # B∆∞·ªõc 3: Gaussian Blur
    print(f"\n[3/9] Gaussian Blur (kernel={gaussian_kernel}, sigma={gaussian_sigma})...")
    t3 = time.time()
    blurred = gaussian_blur(inverted_gray, gaussian_kernel, gaussian_sigma)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t3:.2f}s)")
    
    # B∆∞·ªõc 4: Bilateral Filter (CH·∫¨M NH·∫§T - ƒë√£ t·ªëi ∆∞u)
    print(f"\n[4/9] Bilateral Filter (d={bilateral_kernel})...")
    t4 = time.time()
    blurred = bilateral_filter_optimized(blurred, bilateral_kernel, sigma_color, sigma_space)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t4:.2f}s)")
    
    # B∆∞·ªõc 5: ƒê·∫£o ng∆∞·ª£c ·∫£nh ƒë√£ l√†m m·ªù
    print("\n[5/9] ƒê·∫£o ng∆∞·ª£c ·∫£nh ƒë√£ l√†m m·ªù...")
    t5 = time.time()
    inverted_blurred = invert_image(blurred)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t5:.2f}s)")
    
    # B∆∞·ªõc 6: Ph√°t hi·ªán c·∫°nh
    print("\n[6/9] Ph√°t hi·ªán c·∫°nh (t·∫°o n√©t v·∫Ω)...")
    t6 = time.time()
    edges = detect_edges(gray_image)
    edges_inv = 255 - edges
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t6:.2f}s)")
    
    
    # B∆∞·ªõc 7: Color Dodge Blending
    print("\n[7/9] Color Dodge Blending...")
    t7 = time.time()
    # ƒê·∫£m b·∫£o c√πng k√≠ch th∆∞·ªõc
    if inverted_blurred.shape != gray_image.shape:
        inverted_blurred = resize_image(inverted_blurred, gray_image.shape[1], gray_image.shape[0])
    sketch = color_dodge(gray_image, inverted_blurred)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t7:.2f}s)")
    
    # B∆∞·ªõc 8: K·∫øt h·ª£p n√©t v·∫Ω c·∫°nh
    print("\n[8/9] K·∫øt h·ª£p n√©t v·∫Ω c·∫°nh...")
    t8 = time.time()
    # ƒê·∫£m b·∫£o c√πng k√≠ch th∆∞·ªõc
    if edges_inv.shape != sketch.shape:
        edges_inv = resize_image(edges_inv, sketch.shape[1], sketch.shape[0])
    
    # L√†m ƒë·∫≠m edges
    edges_inv_normalized = edges_inv.astype(np.float32) / 255.0
    edges_inv_normalized = np.power(edges_inv_normalized, 0.6)
    
    sketch = multiply_images(sketch.astype(np.float32) / 255.0, edges_inv_normalized)
    sketch = (sketch * 255).astype(np.uint8)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t8:.2f}s)")
    
    # B∆∞·ªõc 9: ƒêi·ªÅu ch·ªânh Contrast & Brightness
    print("\n[9/9] ƒêi·ªÅu ch·ªânh Contrast & Brightness...")
    t9 = time.time()
    sketch = adjust_contrast(sketch, contrast)
    sketch = np.clip(sketch.astype(np.int16) + brightness, 0, 255).astype(np.uint8)
    
    # Th√™m noise nh·∫π
    noise = np.random.normal(0, 2, sketch.shape).astype(np.int16)
    sketch = np.clip(sketch.astype(np.int16) + noise, 0, 255).astype(np.uint8)
    print(f"  ‚úì Ho√†n th√†nh ({time.time()-t9:.2f}s)")
    
    total_time = time.time() - total_start
    
    print("\n" + "="*60)
    print(f"‚ö° HO√ÄN TH√ÄNH - Th·ªùi gian x·ª≠ l√Ω: {total_time:.2f} gi√¢y")
    print("="*60 + "\n")
    
    return sketch, total_time
